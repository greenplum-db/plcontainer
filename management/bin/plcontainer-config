#!/usr/bin/env python

#------------------------------------------------------------------------------
#
# 
# Copyright (c) 2016-Present Pivotal Software, Inc
#
#------------------------------------------------------------------------------

import os
import sys
import hashlib
import tempfile
import traceback
import datetime
import xml.dom.minidom
from xml.etree import ElementTree
from optparse import OptionParser

try:
    from gppylib import gplog
    from gppylib.commands.base import WorkerPool, REMOTE, Command
    from gppylib.commands.unix import Scp, FileDirExists, getLocalHostname, getUserName
    from gppylib.db import dbconn
    from gppylib import gparray
    from gppylib import userinput
except ImportError, e:
    sys.exit('ERROR: Cannot import Greenplum modules.  Please check that you have sourced greenplum_path.sh.  Detail: ' + str(e))


PLCONTAINER_CONFIG_FILE = 'plcontainer_configuration.xml'
PLCONTAINER_GPDB_DIR = 'share/postgresql/plcontainer'
PL_BATCH_SIZE = 3


def parseargs():
    parser = OptionParser()

    parser.add_option('-s', '--show', action='store_true', help='Show the contents of configuration file without changing it')
    parser.add_option('-v', '--verbose', action='store_true', help='Enable verbose logging')
    parser.add_option('-e', '--editor', type='string', default='vi', help='Editor to use')
    parser.add_option('--reset', action='store_true', help='Reset the configuration file to default')
    parser.add_option('--restore', action='store_true', help='Restore the previous version of PL/Container configuration')
    parser.add_option('--cleanup', action='store_true', help='Remove all the backup files for PL/Container')

    parser.add_option("-c", "--configure", dest="conf", action="store_true", help="Configure container image name and " +
                        "location as well as shared folder, need to combine with -n and -i, usage: -c -n IMAGENAME -i IMAGEURL")
    parser.add_option("-n", "--name", dest="name", type="string", help="Configure container image name")
    parser.add_option("-i", "--image", dest="image", type="string", help="Configure container image location")
    parser.add_option("--volume", dest="shared", type="string", action="append",help="Bind mount a volume, can work with multiple volumes" +
                        " format: HOST:CONTAINER:[rw|ro]")


    (options, args) = parser.parse_args()
    if options.show and (options.reset or options.restore or options.cleanup):
        logger.error(' --show option cannot be combined with --reset, --restore, --cleanup')
        sys.exit(1)
    if options.reset and (options.show or options.restore or options.cleanup):
        logger.error(' --reset option cannot be combined with --show, --restore, --cleanup')
        sys.exit(1)
    if options.restore and (options.show or options.reset or options.cleanup):
        logger.error(' --restore option cannot be combined with --show, --reset, --cleanup')
        sys.exit(1)
    if options.cleanup and (options.show or options.reset or options.restore):
        logger.error(' --cleanup option cannot be combined with --show, --reset, --restore')
        sys.exit(1)
    if options.conf and not (options.name or options.image):
        logger.error(" --configure option needs image name and its location")
        sys.exit(1)
    if (options.name or options.image or options.shared) and not options.conf:
        logger.error(" configuration options must combine with --configure")
        sys.exit(1)

    return options

def update_xml_check_shared_folder(container, elements):
    '''
    update shared folder settings
    '''
    if 'hasShared' in elements.keys():
        for shareDir in container.findall('shared_directory'):
            container.remove(shareDir)
        count = 0
        for plHost in elements['host']:
            shareDir = ElementTree.Element("shared_directory",
                    host=plHost, container=elements['container'][count],
                    access=elements['access'][count])
            count = count + 1
            container.append(shareDir)

def update_xml_container(container, elements):
    '''
    update name and image by given a container node
    '''
    isNew = True
    name = container.find('name').text
    if name == elements['name']:
        if userinput.ask_yesno(None, "This tag is already existed, do you want to overwrite?", 'N'):
            isNew = False
            image = container.find('image')
            image.text = elements['image']
            update_xml_check_shared_folder(container, elements)
    return isNew

def update_xml_new_container(elements):
    '''
    Create a new conatiner node
    '''
    container = ElementTree.Element("container")
    name = ElementTree.Element("name")
    name.text = elements['name']
    image = ElementTree.Element("image")
    image.text = elements['image']

    container.append(name)
    container.append(image)

    update_xml_check_shared_folder(container, elements)

    return container

def update_reformat_xml(xmltree):
    '''
    reformat xml to a pretty print format
    '''
    xmlString = ElementTree.tostring(xmltree)
    reformatString = xml.dom.minidom.parseString(xmlString)
    return reformatString.toprettyxml(indent = '    ') 

def update_xml_config(filename, elements):
    '''
    Update the xml file by given elements dict, if the given tag is
    not existed, then create a new tag. Otherwise, update the current
    tag.
    '''
    isNew = True
    try:
        xmltree = ElementTree.parse(filename)
        logger.info("file name is %s" % (filename))
        root = xmltree.getroot()

        for container in root.findall('container'):
            isNew = update_xml_container(container, elements)
            if not isNew:
                break

        if isNew:
           container = update_xml_new_container(elements)
           root.append(container)

        newXMLTreeString = update_reformat_xml(root)
        newXMLTreeString = os.linesep.join([s for s in newXMLTreeString.splitlines() if not s.strip() == ''])
        xmlfile = open(filename, "w")
        xmlfile.write(newXMLTreeString)
        xmlfile.close()
    except Exception, ex:
        logger.error("Update XML file Error")
        logger.error(str(ex))
        raise Exception("Update XML file Error")

def get_file_md5(file):
    '''
    Generates an MD5 hash of a file.  The hash returned is an array
    of bytes and cannot be printed directly to the screen or log file
    without converting to hex.
    '''
    h = hashlib.md5()
    f = open(file, 'r')
    for l in f:
        h.update(l)
    f.close()
    return h.digest()


def copy_file_to_tmp(host, file):
    """
    Copies file to a local temp file and returns the temp file name.
    While mktemp() is not "safe", the possibilities of this utility
    being run multiple times on the same file and getting the same
    temp filename is so remote that this is acceptable.
    """
    tmp_file = tempfile.mktemp()
    cmd = Scp('copy conf file', file, tmp_file, host)
    cmd.run()
    if not os.path.exists(tmp_file):
        logger.error("Error while copying configuration file. Check that PL/Container is initialized" +
                     " or use --reset to initialize with default configuration")
        tmp_file = None
    return tmp_file


def validate_xml(filename):
    correct = True
    with open(filename, 'rb') as file:
        xmlcontents = file.read()
    try:
        ElementTree.fromstring(xmlcontents)
    except Exception, ex:
        correct = False
        logger.error("XML file does not conform XML specification")
        logger.error(str(ex))
    return correct


def edit_file(filename, editor):
    """
    Starts up options.editor (default is vi) to edit the file.
    """
    edit = True
    while edit:
        distribute = True
        h1 = get_file_md5(filename)
        os.system('%s %s' % (editor, filename))
        h2 = get_file_md5(filename)
        if h1 == h2:
            logger.info("File was not changed, no configuration update is done")
            distribute = False
        validxml = validate_xml(filename)
        if validxml:
            edit = False
        else:
            # If the file is invalid we won't distribute it
            distribute = False
            edit = userinput.ask_yesno(None, "Continue editing the file?", 'N')
    return distribute


def distribute_file(pool, src_filename, dest_filename, gpdb_locations):
    """
    Distributes the edited file to all GPDB instances
    """
    for l in gpdb_locations:
        dest_file = os.path.join(l[1], dest_filename)
        logger.info("Distributing to %s:%s", l[0], dest_file)
        cmd = Scp('distribute changed file',
                  src_filename,
                  dest_file,
                  None,
                  l[0])
        pool.addCommand(cmd)
    pool.join()
    pool.check_results()


def backup_file(pool, gpdb_locations, file):
    """
    Backs up a file to .bak
    """
    timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
    dest_filename = '.' + file + '.bak' + timestamp
    logger.info("Old configuration is saved as '%s'" % dest_filename)
    for l in gpdb_locations:
        src_file = os.path.join(l[1], file)
        dest_file = os.path.join(l[1], dest_filename)
        cmd = Scp('backup file',
                  src_file,
                  dest_file,
                  l[0],
                  l[0])
        pool.addCommand(cmd)
    pool.join()
    pool.check_results()


def get_segment_locations(seg_list):
    """
    Returns a list of tuples that are of the format (hostname, gpdb directory)
    for every segment instance in the cluster.
    """
    gpdb_locations = []
    for s in seg_list:
        gpdb_locations.append((s.getSegmentHostName(), s.getSegmentDataDirectory()))
    return gpdb_locations


def get_last_backup(pool, remote_host, remote_dir, filename):
    """
    Get the last backup file name of PL/Container configuration
    """
    result = None
    filemask = os.path.join(remote_dir, '.' + filename + '.bak*')
    cmdstr = 'ls -1 %s || exit 0' % filemask
    cmd = Command('List PL/Contaner configuartion backups in %s:%s' % (remote_host, remote_dir),
                  cmdstr,
                  ctxt = REMOTE,
                  remoteHost = remote_host)
    cmd.run(validateAfter=True)
    logger.debug("Command executed: '%s'" % cmdstr)
    res = cmd.get_results()
    if res.rc != 0:
        logger.error("Cannot find configuration backup files")
    else:
        if res.stdout.strip() != '':
            files = [x.strip() for x in res.stdout.strip().split('\n')]
            logger.info("Found %d configuration backups" % len(files))
            files = sorted(files)
            for f in files:
                logger.debug("    %s" % f)
            result = files[-1]
        else:
            logger.error("No configuration backups found")
    return result


def remove_files(pool, gpdb_locations, remote_filename):
    """
    Removes the specified file from all the hosts of GPDB cluster
    """
    for l in gpdb_locations:
        remote_file = os.path.join(l[1], remote_filename)
        cmd = Command('Remove %s:%s' % (l[0], remote_file),
                      'rm %s || exit 0' % remote_file,
                      ctxt = REMOTE,
                      remoteHost = l[0])
        pool.addCommand(cmd)
    pool.join()
    pool.check_results()


def show_file(filename):
    logger.info("Configuration file contents:")
    f = open(filename, 'rb')
    sys.stdout.write('%s\n' % f.read())
    f.close()

def get_conf_shared_dir(options, elements):
    '''
    get the shared dirs
    '''
    elements['hasShared'] = True
    shareStrs = options.shared
    elements['host'] = list()
    elements['container'] = list()
    elements['access'] = list()
    for shareStr in shareStrs:
        strList = shareStr.split(":")
        elements['host'].append(strList[0])
        elements['container'].append(strList[1])
        if len(strList) >= 3:
            if strList[2] == "ro" or strList[2] == "rw":
                elements['access'].append(strList[2])
            else:
                raise Exception("Access type can only be \"ro\" or \"rw\". ")
        else:
            elements['access'].append("ro")


def get_conf_elements(options):
    '''
    build an element dict for configuration
    '''
    elements = dict()
    elements['name'] = options.name
    elements['image'] = options.image
    if options.shared:
       get_conf_shared_dir(options, elements)
    return elements

def main():
    pool = None
    tmp_file = None
    options = None
    new_config = False

    options = parseargs()
    if options.verbose:
        gplog.enable_verbose_logging()

    try:
        GPHOME = os.environ.get('GPHOME')
        if not GPHOME:
            raise Exception('$GPHOME environment variable is not set')

        logger.info('Retrieving GPDB configuration from database...')
        url = dbconn.DbURL()
        array = gparray.GpArray.initFromCatalog(url, True)
        segs = array.getDbList()

        gpdb_locations = get_segment_locations(segs)
        logger.debug('GPDB Configuration is:')

        remote_dir = gpdb_locations[0][1]
        remote_host = gpdb_locations[0][0]
        remote_filename = os.path.join(remote_dir, PLCONTAINER_CONFIG_FILE)
        tmp_file = copy_file_to_tmp(remote_host, remote_filename)

        for host, directory in gpdb_locations:
            logger.debug('    host "%s" directory "%s"' % (host, directory))

        if options.show:
            logger.info('Creating temporary copy of %s from %s...' % (remote_filename, remote_host))
            show_file(tmp_file)

        if options.reset:
            logger.info('Preparing the worker pool...')
            pool = WorkerPool(PL_BATCH_SIZE)
            default_config = os.path.join(GPHOME, PLCONTAINER_GPDB_DIR, PLCONTAINER_CONFIG_FILE)
            logger.info('Distributing file %s to all locations...' % default_config)
            distribute_file(pool, default_config, PLCONTAINER_CONFIG_FILE, gpdb_locations)
            new_config = True

        if options.restore:
            logger.info('Getting list of configuration backups in %s:%s...' % (remote_host, remote_dir))
            filename = get_last_backup(pool, remote_host, remote_dir, PLCONTAINER_CONFIG_FILE)
            if filename and userinput.ask_yesno(None, "Continue restoring the backup configuration '%s'?" % filename, 'N'):
                pool = WorkerPool(PL_BATCH_SIZE)
                logger.info('Distributing file %s to all locations...' % PLCONTAINER_CONFIG_FILE)
                distribute_file(pool, tmp_file, PLCONTAINER_CONFIG_FILE, gpdb_locations)
                logger.info('Cleaning up old backup file...')
                remove_files(pool, gpdb_locations, os.path.basename(filename))
                new_config = True

        if options.conf:
            elements = get_conf_elements(options)
            update_xml_config(tmp_file, elements)
            logger.info('Preparing the worker pool...')
            pool = WorkerPool(PL_BATCH_SIZE)
            logger.info('Backing up file %s on all hosts...' % PLCONTAINER_CONFIG_FILE)
            backup_file(pool, gpdb_locations, PLCONTAINER_CONFIG_FILE)
            logger.info('Distributing file %s to all locations...' % PLCONTAINER_CONFIG_FILE)
            distribute_file(pool, tmp_file, PLCONTAINER_CONFIG_FILE, gpdb_locations)
            new_config = True

        if options.cleanup:
            if userinput.ask_yesno(None, "Are you sure want to clean up the PL/Container backup configurations?", 'N'):
                logger.info('Preparing the worker pool...')
                pool = WorkerPool(PL_BATCH_SIZE)
                logger.info('Cleaning up old backup files...')
                remove_files(pool, gpdb_locations, '.' + PLCONTAINER_CONFIG_FILE + '.bak*')

        if not options.reset and not options.restore and not options.show and not options.cleanup and not options.conf:
            changed = edit_file(tmp_file, options.editor)
            if changed:
                logger.info('Preparing the worker pool...')
                pool = WorkerPool(PL_BATCH_SIZE)
                logger.info('Backing up file %s on all hosts...' % PLCONTAINER_CONFIG_FILE)
                backup_file(pool, gpdb_locations, PLCONTAINER_CONFIG_FILE)
                logger.info('Distributing file %s to all locations...' % PLCONTAINER_CONFIG_FILE)
                distribute_file(pool, tmp_file, PLCONTAINER_CONFIG_FILE, gpdb_locations)
                new_config = True

        if new_config:
            logger.info('Configuration has changed. Run "select * from plcontainer_refresh_config" in open sessions.' +
                        ' New sessions will get new configuration automatically')

    except Exception, e:
        logger.fatal("%s failed. (Reason='%s') exiting..." % (execname, e))
        if options.verbose:
            logger.exception(e)

    finally:
        if tmp_file:
            os.unlink(tmp_file)
        if pool:
            logger.info('Shutting down workers...')
            pool.haltWork()
            pool.joinWorkers()
        logger.info('Done')


if __name__ == '__main__':
    execname = os.path.split(__file__)[-1]
    gplog.setup_tool_logging(execname, getLocalHostname(), getUserName())
    logger = gplog.get_default_logger()
    main()

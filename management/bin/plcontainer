#!/usr/bin/env python

#------------------------------------------------------------------------------
#
# Copyright (c) 2016, Pivotal.
#
#------------------------------------------------------------------------------

import os
import sys
import time
from xml.etree import ElementTree
from optparse import OptionParser
import commands

try:
    from gppylib import gplog
    from gppylib.commands.base import WorkerPool, REMOTE, Command
    from gppylib.commands.unix import Scp, FileDirExists, getLocalHostname, getUserName
    from gppylib.db import dbconn
    from gppylib import gparray
    from gppylib import userinput
except ImportError, e:
    sys.exit('ERROR: Cannot import Greenplum modules.  Please check that you have sourced greenplum_path.sh.  Detail: ' + str(e))

global GPHOME

PLCONTAINER_GPDB_DIR = 'share/postgresql/plcontainer'
TMP = '/tmp'
OPERATE_LIST = ['image'] 
TAR_GZ = '.tar.gz'

def parseargs():
    parser = OptionParser()

    parser.add_option('-i', '--install', dest='image', type='string', help='Tar.gz image file or docker image url to be installed')
    parser.add_option('-f', '--hostfile', dest='hostfile',type='string', help='Greenplum cluster hostfile')
    parser.add_option('-v', '--verbose', action='store_true', help='Enable verbose logging')
    parser.add_option('--batch-size', type='int', default='3')

    (options, args) = parser.parse_args()

    if len(args) != 1 :
        parser.print_help()
        sys.exit(1)

    if args[0] not in OPERATE_LIST:
        logger.error('Currently only support operate %s' % OPERATE_LIST)
        parser.print_help()
        sys.exit(1)

    return (options, args)

def close_pool(pool):
    logger.info('Shutting down workers...')
    pool.haltWork()
    pool.joinWorkers()

def distributed_file(pool, d_file, dest, hfile):
    if dest is None:
        dest = os.path.join(TMP, d_file)
    with open(hfile) as f:
        for host in f:
            cmd = Scp('Distribute docker image file.',
                      d_file,
                      dest,
                      None,
                      host.strip())
            pool.addCommand(cmd)
    pool.join()
    pool.check_results()

def remote_cmd(pool, cmd_str, hfile):
    with open(hfile) as f:
        for host in f:
            cmd = Command('Execute remote cmd on all hosts.',
                          cmd_str,
                          ctxt = REMOTE,
                          remoteHost = host.strip())
            pool.addCommand(cmd)
    pool.join()
    pool.check_results()

def get_docker_image(url):
    logger.info("Getting docker image from %s" % url)
    (ok, out) = commands.getstatusoutput('docker pull %s' % url)
    if ok != 0:
        logger.error("Cannot pull docker image from %s" % url)
        sys.exit(1)
    name_tag = url.split("/")[-1]
    image_name = "".join([name_tag.replace(":", "_"), TAR_GZ])
    image_path = os.path.join(TMP, image_name)
    logger.info("Saving docker image to %s" % image_path)
    (ok, out) = commands.getstatusoutput('docker save -o %s %s' % (image_path, url))
    if ok != 0:
        logger.error("Cannot save docker image %s to %s" % (url, image_path))
        sys.exit(1)

    return image_path

def install_images(options, args):
    logger.info('Starting to install images %s on hosts in %s' % (options.image, options.hostfile))
    docker_image = options.image
    hostfile = options.hostfile
    if hostfile is None or not os.path.isfile(hostfile):
        logger.error('Hostfile %s is not exist. Please specify hostfile.' % hostfile)
        sys.exit(1)

    if docker_image is None:
        logger.error('Docker image cannot be none.')
        sys.exit(1)
    if not docker_image.endswith(TAR_GZ):
        docker_image = get_docker_image(options.image)

    try:
        logger.info('Checking docker installed on all hosts...')
        check_docker_cmd = 'which docker'
        pool = WorkerPool(options.batch_size)
        remote_cmd(pool, check_docker_cmd, hostfile)
        close_pool(pool)

        logger.info('Distributing image file %s to all hosts...' % docker_image)
        dest = os.path.join(GPHOME, PLCONTAINER_GPDB_DIR, docker_image)
        pool = WorkerPool(options.batch_size)
        distributed_file(pool, docker_image, dest, hostfile)
        close_pool(pool)

        logger.info('Loading image on all hosts...')
        docker_load_cmd = " ".join(["docker load -i ", dest])
        pool = WorkerPool(options.batch_size)
        remote_cmd(pool, docker_load_cmd, hostfile)
        close_pool(pool)

    except Exception, e:
        logger.fatal("%s failed. (Reason='%s') exiting..." % (execname, e))
        if pool:
            close_pool(pool)
        if options.verbose:
            logger.exception(e)
        sys.exit(1)

def main():
    (options, ARGS) = parseargs()

    if options.verbose:
        gplog.enable_verbose_logging()

    global GPHOME
    GPHOME = os.environ.get('GPHOME')
    if not GPHOME:
        raise Exception('$GPHOME environment variable is not set')

    if ARGS[0] == 'image':
        install_images(options, ARGS)

    logger.info('Done')


if __name__ == '__main__':
    execname = os.path.split(__file__)[-1]
    gplog.setup_tool_logging(execname, getLocalHostname(), getUserName())
    logger = gplog.get_default_logger()
    main()
